# source code: https://github.com/inclusionAI/AWorld/blob/main/examples/gaia/mcp_collections/tools/browser.py
import asyncio, json, os, re, sys, time, traceback, subprocess
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    print("âš ï¸  psutil not available - limited cleanup capabilities")
from browser_use import Agent, AgentHistoryList, BrowserProfile
from browser_use.llm import ChatOpenAI
from pathlib import Path
from pydantic import BaseModel, Field
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__),'..', '..', '..')))
from opentools.core.base import BaseTool

class BrowserMetadata(BaseModel):
    """Metadata for browser automation results."""

    task: str
    execution_successful: bool
    steps_taken: int | None = None
    downloaded_files: list[str] = Field(default_factory=list)
    visited_urls: list[str] = Field(default_factory=list)
    execution_time: float | None = None
    error_type: str | None = None
    trace_log_path: str | None = None


class Browser_Interaction_Tool(BaseTool):
    """
    Browser_Interaction_Tool
    ---------------------
    Purpose:
        A tool for interacting with web browsers, providing comprehensive automation capabilities including web scraping, form submission, file downloads, and LLM-enhanced browsing with memory. Ideal for information gathering/retrieval, news gathering, data collection, and web automation tasks. Works best when combined with Search_Engine_Tool to first find relevant URLs, then browse those URLs for detailed information.

    Core Capabilities:
        - Web scraping and content extraction
        - Form submission and interaction
        - File downloads and media handling
        - LLM-enhanced browsing with memory
        - Robot detection and paywall handling

    Intended Use:
        Use this tool when you need to interact with web browsers, providing comprehensive automation capabilities including web scraping, form submission, file downloads, and LLM-enhanced browsing with memory. Ideal for information gathering/retrieval, news gathering, data collection, and web automation tasks. Works best when combined with Search_Engine_Tool to first find relevant URLs, then browse those URLs for detailed information.

    Limitations:
        - Requires a web browser to be installed and available on the host system
        - Requires a valid OpenAI API key and internet connectivity
        - May get stuck on certain websites, blocked by anti-bot measures, or fail to extract data from heavily JavaScript-dependent sites
    """
    # Default args for `opentools test Browser_Interaction_Tool` (uses test_file/data.json)
    DEFAULT_TEST_ARGS = {
        "tool_test": "browser_interaction",
        "file_location": "browser_interaction",
        "result_parameter": "result",
        "search_type": "similarity_eval",
    }

    # Configuration constants
    DEFAULT_MAX_STEPS = 50
    MIN_MAX_STEPS = 30
    DEFAULT_EXTRACT_FORMAT = "json"
    DEFAULT_TEMPERATURE = 0.1
    
    def __init__(self, llm_engine=None, model_string="gpt-5-mini"):
        super().__init__(
            type='function',
            name="Browser_Interaction_Tool",
            description="""An AI-powered web research assistant that intelligently browses websites, extracts information, and automates complex web tasks. 
            Like having a research assistant available, it can find, analyze, and compile information from across the entire web with high accuracy. 
            Perfect for information gathering/retrieval, news gathering, data collection, and web automation tasks. 
            Works best when combined with Search_Engine_Tool to first find relevant URLs, then browse those URLs for detailed information.
            CAPABILITIES: Web scraping and content extraction and automated interactions, LLM-enhanced browsing, automatic URL extraction, 
            SYNONYMS: web automation, web scraping, web research assistant, automated browsing web data extraction, AI browser, intelligent web assistant, web automation tool. """,
            parameters={
                "type": "object",
                "properties": {
                    "task": {
                        "type": "string",
                        "description": "The task to perform (e.g., 'search for information', 'browse websites')"
                    },
                    "max_steps": {
                        "type": "integer",
                        "description": "Maximum number of browser automation steps (default: 50). Min should be 30"
                    },
                    "extract_format": {
                        "type": "string",
                        "description": "Output format: 'markdown', 'json', or 'text' (default: 'json')",
                        "enum": ["markdown", "json", "text"]
                    }
                },
                "required": ["task"],
                "additionalProperties": False,
            },
            strict=False,
            category="web_automation",
            tags=["web_scraping", "browser_automation", "web_research", "content_extraction", "ai_browser", "web_crawler"],
            limitation="HIGH COST WARNING: This tool consumes significant OpenAI API tokens which can be expensive for complex tasks. RELIABILITY ISSUES: May get stuck on certain websites, blocked by anti-bot measures, or fail to extract data from heavily JavaScript-dependent sites.",
            agent_type="Browser_Extraction-Agent",
            accuracy= self.find_accuracy(os.path.join(os.path.dirname(__file__), 'test_result.json')),
            demo_commands= {
                "command": "reponse = tool.run(task='Who is the current president of the United States?')",
                "description": "Find the current president of the United States"
            },
            require_llm_engine=True,
            llm_engine=llm_engine,
            model_string=model_string,
            )
        self.workspace = Path(os.getcwd())
        self.extended_browser_system_prompt = """
10. URL ends with .pdf
- If the go_to_url function with `https://any_url/any_file_name.pdf` as the parameter, just report the url link and hint the user to download using `download` mcp tool or `curl`, then execute `done` action.

11. Robot Detection:
- If the page is a robot detection page, abort immediately. Then navigate to the most authoritative source for similar information instead

# Efficiency Guidelines
0. DO NOT automatically download files unless specifically requested. Only report download URLs when found.
1. Use specific search queries with key terms from the task
2. Avoid getting distracted by tangential information
3. If blocked by paywalls, try archive.org or similar alternatives
4. Document each significant finding clearly and concisely
5. Precisely extract the necessary information with minimal browsing steps.
6. Avoid downloading or playing media files (videos, audio) unless explicitly requested.
"""

        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required but not set")
        
        # Initialize LLM configuration
        if self.model_string.startswith("gpt-5"):
            self.llm_config = ChatOpenAI(
                model= model_string,
                api_key=openai_api_key,
            )
        else:
            self.llm_config = ChatOpenAI(
                model= model_string,
                api_key=openai_api_key,
                temperature=self.DEFAULT_TEMPERATURE,  
            )

        # Browser profile configuration
        # Check if we have a display available, otherwise run headless
        has_display = os.getenv("DISPLAY") is not None
        
        # Disable browser-use cloud sync to avoid authentication warnings
        # This is optional and doesn't affect browser functionality
        os.environ.setdefault("BROWSER_USE_DISABLE_SYNC", "1")
        
        self.browser_profile = BrowserProfile(
            cookies_file=os.getenv("COOKIES_FILE_PATH"),
            chromium_sandbox=False,
            headless=not has_display,  # Run headless if no display available
        )

        # Log configuration
        self.trace_log_dir = str(self.workspace / "logs")
        try:
            os.makedirs(f"{self.trace_log_dir}/browser_log", exist_ok=True)
        except Exception as e:
            print(f"Warning: Could not create log directory: {e}")
            # Fallback to workspace directory
            self.trace_log_dir = str(self.workspace)
        
        # Fix Unicode encoding issues on Windows
        import logging
        import sys
        
        # Configure logging to handle Unicode properly
        if sys.platform == "win32":
            # Set console encoding to UTF-8
            if hasattr(sys.stdout, 'reconfigure'):
                sys.stdout.reconfigure(encoding='utf-8')
            if hasattr(sys.stderr, 'reconfigure'):
                sys.stderr.reconfigure(encoding='utf-8')
            
            # Configure logging to handle Unicode
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                handlers=[
                    logging.StreamHandler(sys.stdout),
                    logging.FileHandler(f"{self.trace_log_dir}/browser_log/browser.log", encoding='utf-8')
                ]
            )

    def _cleanup_stale_browser_processes(self):
        """Clean up stale browser processes and SingletonLock files.
        
        This method handles cases where previous browser instances didn't shut down
        properly, leaving behind lock files that prevent new instances from starting.
        """
        try:
            # Default browser profile directory used by browser-use
            profile_dir = Path.home() / ".config" / "browseruse" / "profiles" / "default"
            singleton_lock = profile_dir / "SingletonLock"
            
            print(f"ðŸ§¹ Starting browser cleanup...", flush=True)
            
            # FIRST: Remove SingletonLock file if it exists (sometimes this is enough)
            if singleton_lock.exists():
                print(f"âš ï¸  Found SingletonLock file, attempting removal...", flush=True)
                try:
                    singleton_lock.unlink()
                    print(f"âœ… Removed SingletonLock file", flush=True)
                    time.sleep(0.3)
                except Exception as e:
                    print(f"âš ï¸  Could not remove SingletonLock yet (will retry after killing processes): {e}", flush=True)
            
            # SECOND: Aggressively kill any chrome/chromium processes using the browseruse profile
            # Use multiple methods to ensure we catch all processes
            try:
                # Method 1: Kill by profile directory path
                profile_path = str(profile_dir).replace('/', '\/')
                subprocess.run(['pkill', '-9', '-f', f'user-data-dir.*{profile_path}'], 
                             check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(0.3)
                
                # Method 2: Kill by browseruse in path
                subprocess.run(['pkill', '-9', '-f', 'browseruse.*profiles'], 
                             check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(0.3)
                
                # Method 3: Kill any chrome/chromium with the specific profile directory
                subprocess.run(['pkill', '-9', '-f', 'browseruse/profiles/default'], 
                             check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(0.3)
                
                # Method 4: Kill chromium processes from playwright cache (these are automation browsers)
                # This is safe because these are only automation browsers, not user browsers
                subprocess.run(['pkill', '-9', '-f', 'ms-playwright.*chromium'], 
                             check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(0.5)
                print(f"âœ… Killed automation browser processes", flush=True)
            except Exception as e:
                print(f"âš ï¸  Error in aggressive cleanup: {e}", flush=True)
            
            # Always try to kill any chromium/chrome processes that might be using the profile
            killed_any = False
            if HAS_PSUTIL:
                try:
                    # Find chromium/chrome processes that might be using this profile
                    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                        try:
                            cmdline = proc.info.get('cmdline', [])
                            if cmdline:
                                cmdline_str = ' '.join(cmdline)
                                # Check if this process is using the browser profile
                                # Look for processes with the profile directory or browseruse in path
                                profile_str = str(profile_dir)
                                if (('chromium' in cmdline_str.lower() or 'chrome' in cmdline_str.lower()) and 
                                    ('browseruse' in cmdline_str or profile_str in cmdline_str or 
                                     'user-data-dir' in cmdline_str)):
                                    pid = proc.info['pid']
                                    print(f"ðŸ”ª Killing stale browser process PID {pid}")
                                    try:
                                        proc.kill()
                                        proc.wait(timeout=2)
                                        killed_any = True
                                    except (psutil.NoSuchProcess, psutil.TimeoutExpired):
                                        # Process already dead or not responding, force kill
                                        try:
                                            proc.kill()
                                        except:
                                            pass
                                    time.sleep(0.5)
                        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                            # Process already gone or we can't access it
                            continue
                except Exception as e:
                    print(f"âš ï¸  Could not kill stale processes with psutil: {e}")
            else:
                # Fallback: try using pgrep/pkill if psutil is not available
                try:
                    # Kill any chrome/chromium processes with browseruse profile
                    for pattern in ['browseruse.*profiles.*default', 'user-data-dir.*browseruse']:
                        result = subprocess.run(
                            ['pgrep', '-f', pattern],
                            capture_output=True,
                            text=True
                        )
                        if result.returncode == 0:
                            pids = result.stdout.strip().split('\n')
                            for pid in pids:
                                if pid.strip():
                                    print(f"ðŸ”ª Killing stale browser process PID {pid.strip()}")
                                    subprocess.run(['kill', '-9', pid.strip()], check=False)
                                    killed_any = True
                                    time.sleep(0.5)
                except Exception as e:
                    print(f"âš ï¸  Could not kill stale processes (fallback method): {e}")
            
            # THIRD: Try to remove SingletonLock file again if it still exists (after killing processes)
            if singleton_lock.exists():
                print(f"âš ï¸  SingletonLock still exists, attempting removal again...", flush=True)
                try:
                    time.sleep(0.5)  # Give processes time to release the lock
                    singleton_lock.unlink()
                    print(f"âœ… Removed SingletonLock file (after process cleanup)", flush=True)
                except Exception as e:
                    print(f"âš ï¸  Could not remove SingletonLock: {e}", flush=True)
                    # Last resort: try to remove the entire profile directory
                    try:
                        import shutil
                        if profile_dir.exists():
                            print(f"ðŸ—‘ï¸  Attempting to remove entire profile directory...", flush=True)
                            shutil.rmtree(profile_dir)
                            print(f"âœ… Removed profile directory", flush=True)
                    except Exception as e2:
                        print(f"âš ï¸  Could not remove profile directory: {e2}", flush=True)
            else:
                print(f"âœ… No SingletonLock file found (clean)", flush=True)
                        
        except Exception as e:
            print(f"âš ï¸  Error during browser cleanup: {e}")
            import traceback
            traceback.print_exc()
            # Don't fail the entire operation if cleanup fails

    def _create_browser_agent(self, task: str) :
        """Create a browser agent instance with configured settings.

        Args:
            task: The task description for the browser agent

        Returns:
            Configured Agent instance
        """
        return Agent(
            task=task,
            llm=self.llm_config,
            extend_system_message=self.extended_browser_system_prompt,
            use_vision=True,
            enable_memory=False,
            browser_profile=self.browser_profile,
            save_conversation_path=f"{self.trace_log_dir}/browser_log/trace.log",
        )

    def _extract_visited_urls(self, extracted_content: list[str]) -> list[str]:
        """Inner method to extract URLs from content using regex.

        Args:
            content_list: List of content strings to search for URLs

        Returns:
            List of unique URLs found in the content
        """
        url_pattern = r'https?://[^\s<>"\[\]{}|\\^`]+'
        visited_urls = set()

        for content in extracted_content:
            if content and isinstance(content, str):
                urls = re.findall(url_pattern, content)
                visited_urls.update(urls)

        return list(visited_urls)

    def _format_extracted_content(self, extracted_content: list[str]) -> str:
        """Format extracted content to be LLM-friendly.

        Args:
            extracted_content: List of extracted content strings from browser execution

        Returns:
            Formatted string suitable for LLM consumption
        """
        if not extracted_content:
            return "No content extracted from browser execution."

        # Handle list of strings
        if len(extracted_content) == 1:
            # Single item - return it directly with formatting
            return f"**Extracted Content:**\n{extracted_content[0]}"
        else:
            # Multiple items - format as numbered list
            formatted_parts = ["**Extracted Content:**"]
            for i, content in enumerate(extracted_content, 1):
                if content.strip():  # Only include non-empty content
                    formatted_parts.append(f"{i}. {content}")

            return (
                "\n".join(formatted_parts)
                if len(formatted_parts) > 1
                else "No meaningful content extracted from browser execution."
            )

    def run(
        self,
        task: str = None,
        max_steps: int = DEFAULT_MAX_STEPS,
        extract_format: str = DEFAULT_EXTRACT_FORMAT,
    ) :
        """Synchronous wrapper for the async browser automation."""
        # Validate required parameters
        if not task:
            return {
                "error": "Error: 'task' parameter is required and cannot be empty",
                "metadata": BrowserMetadata(
                    task=task,
                    execution_successful=False,
                    error_type="missing_required_parameter"
                ).model_dump(),
                "success": False
            }
        
        # Validate max_steps
        if max_steps < self.MIN_MAX_STEPS:
            max_steps = self.MIN_MAX_STEPS
            print(f"Warning: max_steps adjusted to minimum value of {self.MIN_MAX_STEPS}")
        
        try:
            # Check if we're already in an event loop
            try:
                loop = asyncio.get_running_loop()
                # If we're in an event loop, we need to create a new thread
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self._run_async(task, max_steps, extract_format))
                    return future.result()
            except RuntimeError:
                # No event loop running, we can use asyncio.run directly
                return asyncio.run(self._run_async(task, max_steps, extract_format))
        except Exception as e:
            return {
                "error": f"Browser automation error: {str(e)}",
                "traceback": traceback.format_exc(),
                "metadata": BrowserMetadata(
                    task=task,
                    execution_successful=False,
                    error_type="execution_error"
                ).model_dump(),
                "success": False
            }

    async def _run_async(
        self,
        task: str = None,
        max_steps: int = DEFAULT_MAX_STEPS,
        extract_format: str = DEFAULT_EXTRACT_FORMAT,
    ) :
        """Perform browser automation tasks using the browser-use package.

        This tool provides comprehensive browser automation capabilities including:
        - Web scraping and content extraction
        - Form submission and automated interactions
        - File downloads and media handling
        - LLM-enhanced browsing with memory and vision
        - Automatic handling of robot detection and paywalls

        Args:
            task: Description of the browser automation task to perform
            max_steps: Maximum number of execution steps (default: 50)
            extract_format: Output format for extracted content

        Returns:
            ActionResponse with LLM-friendly extracted content and execution metadata
        """
        try:
            print(f"ðŸŽ¯ Starting browser task: {task}")

            # Validate task is not empty
            if not task or not task.strip():
                raise ValueError("Task cannot be empty or whitespace")

            # Clean up any stale browser processes before starting
            self._cleanup_stale_browser_processes()
            
            # Give cleanup time to complete and filesystem to sync
            time.sleep(1.0)
            print(f"âœ… Cleanup complete, proceeding with browser launch...", flush=True)

            # Create browser agent
            agent = self._create_browser_agent(task)

            start_time = time.time()
            token_usage_from_agent = None  # Initialize before try block

            try:
                browser_execution: AgentHistoryList = await agent.run(max_steps=max_steps)
                
                # Extract token usage from agent's token service after execution
                token_usage_from_agent = None
                try:
                    if hasattr(agent, 'token_cost_service'):
                        token_service = agent.token_cost_service
                        if hasattr(token_service, 'get_usage_summary'):
                            # get_usage_summary() is async and returns UsageSummary object
                            usage = await token_service.get_usage_summary()
                            if usage:
                                # Extract from UsageSummary object attributes
                                # Get model from by_model dict if available
                                model = "unknown"
                                if hasattr(usage, 'by_model') and usage.by_model:
                                    model = list(usage.by_model.keys())[0] if isinstance(usage.by_model, dict) else "unknown"
                                
                                token_usage_from_agent = {
                                    "total_tokens": getattr(usage, 'total_tokens', 0),
                                    "prompt_tokens": getattr(usage, 'total_prompt_tokens', 0),
                                    "completion_tokens": getattr(usage, 'total_completion_tokens', 0),
                                    "model": model,
                                    "calls": getattr(usage, 'entry_count', 0),
                                }
                except Exception:
                    # Token tracking is optional, don't fail if it's not available
                    pass
            except UnicodeEncodeError as e:
                # Handle Unicode encoding errors from browser-use logging
                print(f"Warning: Unicode encoding issue in browser logging: {e}")
                # Try to get the result anyway by creating a mock execution
                class MockExecution:
                    def is_done(self): return True
                    def is_successful(self): return True
                    def extracted_content(self): return ["Task completed but logging had encoding issues"]
                    def final_result(self): return "Task completed successfully"
                    def history(self): return []
                
                browser_execution = MockExecution()
                token_usage_from_agent = None
            except Exception as run_error:
                # Catch all other exceptions during agent.run() to provide better error messages
                print(f"âŒ Exception during browser agent.run(): {type(run_error).__name__}: {str(run_error)}")
                print(f"   Traceback: {traceback.format_exc()}")
                # Set browser_execution to None so it fails the check below
                browser_execution = None
                token_usage_from_agent = None

            execution_time = time.time() - start_time

            # Debug logging to understand failure
            if browser_execution is None:
                print(f"âŒ Browser execution is None")
            elif not browser_execution.is_done():
                print(f"âŒ Browser execution not done. Steps taken: {len(browser_execution.history) if hasattr(browser_execution, 'history') else 'unknown'}")
            elif not browser_execution.is_successful():
                print(f"âŒ Browser execution not successful. Final result: {browser_execution.final_result() if hasattr(browser_execution, 'final_result') else 'N/A'}")
                if hasattr(browser_execution, 'history') and browser_execution.history:
                    print(f"   Last action: {browser_execution.history[-1] if len(browser_execution.history) > 0 else 'N/A'}")

            if (
                browser_execution is not None
                and browser_execution.is_done()
                and browser_execution.is_successful()
            ):
                # Extract and format content
                extracted_content = browser_execution.extracted_content()
                final_result = browser_execution.final_result()

                # Use token usage extracted above
                token_usage = token_usage_from_agent

                # Format content based on requested format
                if extract_format.lower() == "json":
                    formatted_content = json.dumps(
                        {"summary": final_result, "extracted_data": extracted_content},
                        indent=2,
                    )
                elif extract_format.lower() == "text":
                    formatted_content = f"{final_result}\n\n{self._format_extracted_content(extracted_content)}"
                else:  # markdown (default)
                    formatted_content = (
                        f"## Browser Automation Result\n\n**Summary:** {final_result}\n\n"
                        f"{self._format_extracted_content(extracted_content)}"
                    )
                metadata = BrowserMetadata(
                    task=task,
                    execution_successful=True,
                    steps_taken=(
                        len(browser_execution.history)
                        if hasattr(browser_execution, "history")
                        else None
                    ),
                    downloaded_files=[],
                    visited_urls=self._extract_visited_urls(extracted_content),
                    execution_time=execution_time,
                    trace_log_path=f"{self.trace_log_dir}/browser_log/trace.log",
                )
                return {
                    "result": formatted_content,
                    "metadata": metadata.model_dump(),
                    "success": True,
                    "token_usage": token_usage,
                }

            else:
                # Handle execution failure - provide more detailed error message
                error_details = []
                if browser_execution is None:
                    error_details.append("browser_execution is None")
                elif not browser_execution.is_done():
                    steps = len(browser_execution.history) if hasattr(browser_execution, 'history') else 0
                    error_details.append(f"execution not completed (steps: {steps}/{max_steps})")
                elif not browser_execution.is_successful():
                    final_result = browser_execution.final_result() if hasattr(browser_execution, 'final_result') else "N/A"
                    error_details.append(f"execution not successful (result: {final_result})")
                
                error_msg = f"Browser execution failed or was not completed successfully"
                if error_details:
                    error_msg += f" - {', '.join(error_details)}"

                # Try to get token usage even on failure
                token_usage = None
                try:
                    if hasattr(self.llm_config, 'get_token_usage'):
                        token_usage = self.llm_config.get_token_usage()
                except Exception:
                    pass

                return {
                    "error": error_msg,
                    "metadata": BrowserMetadata(
                        task=task,
                        execution_successful=False,
                        error_type="execution_error",

                    ).model_dump(),
                    "success": False,
                    "token_usage": token_usage,
                }

        except Exception as e:
            error_msg = f"Browser automation failed: {str(e)}"
            error_trace = traceback.format_exc()

            # Try to get token usage even on exception
            token_usage = None
            try:
                if hasattr(self.llm_config, 'get_token_usage'):
                    token_usage = self.llm_config.get_token_usage()
            except Exception:
                pass

            return {
                "error": f"{error_msg}\n\nError details: {error_trace}",
                "traceback": error_trace,
                "metadata": BrowserMetadata(
                    task=task,
                    execution_successful=False,
                    error_type="execution_error",
                ).model_dump(),
                "success": False,
                "token_usage": token_usage,
            }

    def test(self, tool_test: str="browser_interaction", file_location: str="browser_interaction", result_parameter: str="result", search_type: str="search_pattern"):
        return super().test(tool_test=tool_test, file_location=file_location, result_parameter=result_parameter, search_type=search_type)

# Example usage and entry point
if __name__ == "__main__":

    # Initialize and run the browser automation service
    try:
        tool = Browser_Interaction_Tool()
        # tool.embed_tool()
        print(tool.run(task='What is the capital of Vietnam?'))
        # tool.test(tool_test="browser_interaction", file_location="browser_interaction", result_parameter="result", search_type='search_pattern')
    except Exception as e:
        print(f"An error occurred: {e}: {traceback.format_exc()}")      
