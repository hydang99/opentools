# OpenTools Agents

This directory contains agent implementations and the shared agent framework. Agents provide different reasoning styles and tool-usage strategies while sharing a common interface.

---

## Directory and file roles

| Path | Role |
|------|------|
| **`base_agent.py`** | Minimal base for all agents. Defines the interface: `get_agent_name()`, `get_agent_description()`, `solve()`. Uses `AgentDisplayMixin` for logging and step tracking. No tools. |
| **`tool_based_agent.py`** | Base for agents that use tools. Composes `ToolCapabilityMixin`, sets up tool discovery/executor (and optional FAISS retrieval), and requires subclasses to implement `setup_reasoning_components()`. |
| **`agent_manager.py`** | Registry and factory: registers agent names → classes, and provides `create_agent()`, `list_agents()`, `register_agent()`. |
| **`file_retrieval.py`** | Retrieval over long text (e.g. large tool outputs). Provides `TextHybridRetriever`: hybrid (BM25 + semantic) retrieval so the agent can pull only relevant snippets when tool output exceeds a token limit. |
| **`mixins/`** | Reusable behavior mixed into agents. |
| **`mixins/tool_capability_mixin.py`** | Tool discovery, normalization of tool calls, execution, optional FAISS tool retrieval, and optional retrieval on large tool results. Used by `ToolBasedAgent` and (when tools are enabled) by CoT and ZeroShot. |
| **`embeddings/`** | Stores **tool embeddings** (e.g. `tool_embeddings.json`). Generated by `BaseTool.embed_tool()`; used by `ToolRetriever` for FAISS-based “relevant tools for this question” when `enable_faiss_retrieval=True`. |
| **`react/`** | ReAct agent: Thought → Action (tool) → Observation loop until Final Answer. |
| **`opentools/`** | OpenTools agent: multi-step loop with Reasoning (sub-problem + sub-agent) → Generator/Verifier, global and local memory, optional retrieval on large outputs. |
| **`octotools/`** | OctoTools agent: planning + memory + step-by-step execution; compatible with the original OctoTools pipeline (planner, executor, cache). |
| **`chain_of_thought/`** | Chain-of-thought agent: step-by-step reasoning; tools optional. |
| **`zero_shot/`** | Zero-shot agent: single direct LLM response; tools optional. |

---

## Difference between agents (ReAct, OpenTools, OctoTools, CoT, ZeroShot)

| Agent | Tools | Reasoning style | When to use |
|-------|--------|-----------------|-------------|
| **ReAct** | Yes (core) | **Thought → Action → Observation** in a loop. One “thought” and one tool call per step; continues until a “Final Answer”. | Tasks that need iterative tool use and explicit reasoning steps (search, calc, extract, then answer). |
| **OpenTools** | Yes (core) | **Multi-agent loop**: Reasoning picks a sub-problem and sub-agent type; then generator/verifier and memory (global + local). Can run retrieval on very large tool outputs. | Complex, multi-step tasks with clear sub-tasks and need for verification/summary. |
| **OctoTools** | Yes (core) | **Plan then execute**: Planner produces a base response and plan; dedicated executor and memory run the steps. Matches the original OctoTools flow. | When you want a distinct planning phase and a separate execution phase. |
| **Chain-of-thought (CoT)** | Optional | **Step-by-step reasoning** in the prompt; no tool loop by default. Can enable tools so the model can call tools during reasoning. | Logic/math/reasoning-heavy questions; optional tools for lookup or computation. |
| **Zero-shot** | Optional | **Single direct answer** from the LLM; no reasoning loop. Can enable tools for one-shot tool use. | Fast, simple Q&A; optional tools when one call is enough. |

Summary:

- **ReAct**: loop of think + act + observe until done.
- **OpenTools**: loop of reason (sub-problem + sub-agent) → generate/verify with memory; handles huge tool outputs via retrieval.
- **OctoTools**: plan first, then execute with executor and memory.
- **CoT**: step-by-step reasoning; tools are optional.
- **Zero-shot**: one-shot answer; tools are optional.

---

## Embeddings and mixins

**Embeddings (`embeddings/`, `tool_embeddings.json`)**

- **What**: Vector embeddings of tool metadata (name, description, category, tags) for semantic search.
- **How they’re created**: When you call `BaseTool.embed_tool()` (e.g. from a tool’s `__main__` or a script), the tool’s metadata is embedded (e.g. via OpenAI embeddings) and stored under `agents/embeddings/tool_embeddings.json`.
- **How they’re used**: `ToolRetriever` (in `core/tool_retrieval.py`) loads this file, builds a FAISS index, and returns the top-k tools for a given question. Agents that set `enable_faiss_retrieval=True` use this to pass only relevant tools to the LLM instead of the full toolbox.

**Mixins (`mixins/`)**

- **ToolCapabilityMixin** (`mixins/tool_capability_mixin.py`): Provides tool discovery (initializer), execution (executor), normalization of tool calls, optional FAISS tool retrieval, and optional retrieval on large tool results. Used by `ToolBasedAgent` and by CoT/ZeroShot when `enable_tool_calls=True`. See that file’s docstrings for each method.

**File retrieval (`file_retrieval.py`)**

- Used when a tool returns very long text (e.g. >30k tokens). The mixin can call a retriever (e.g. `TextHybridRetriever`) on the tool output with a short query so the agent only sees the relevant part instead of the full blob.

---

## Agent registry and usage

**Registry**

- `AgentManager` holds the mapping from string name → agent class. Default names: `react`, `opentools`, `octotools`, `chain_of_thought`, `zero_shot`.
- Use `create_agent(name, llm_engine_name, **kwargs)` and `list_agents()` from `opentools.agents`.

**Example**

```python
from opentools.agents import create_agent, list_agents

print(list_agents())
agent = create_agent("react", llm_engine_name="gpt-4o-mini", enabled_tools=["all"])
result = agent.solve("What is the capital of France?")
```

**Common parameters (tool-based agents)**

- `enabled_tools`: List of tool class names or `["all"]`.
- `enable_faiss_retrieval`: Use FAISS over tool embeddings to pass only relevant tools.
- `num_threads`, `max_time`, `max_output_length`: Execution limits.
- `vllm_config_path`: vLLM config when using a vLLM model.

**Typical result shape**

- `solve()` usually returns a dict with: `query`, `image`, `agent`, `llm_engine`, `steps_taken`, `execution_time`, `timestamp`, and one or more of `direct_output`, `final_output`, `base_output`, `full_answer`; optionally `token_usage`, `reasoning_trace`, `error_executions`, etc.

---

## How to add an agent

### 1. Create the module and class

Add a folder and entry point, e.g.:

```
src/opentools/agents/my_agent/
  __init__.py   # export the agent class
  agent.py      # implement the agent
```

### 2. Implement the agent

- **Without tools**: inherit `BaseAgent`, implement `get_agent_name()`, `get_agent_description()`, `solve(question, **kwargs)`.
- **With tools**: inherit `ToolBasedAgent`, implement `setup_reasoning_components()` and `solve()`. Use `get_relevant_tools(question)`, `execute_tool(tool_calls, question)`, etc. from the mixin.

### 3. Register the agent

- In `agent_manager.py`: import your class and in `_register_default_agents()` call `self.register_agent("my_agent", MyAgent)`.
- Or from outside: `from opentools.agents import register_agent; register_agent("my_agent", MyAgent)` (before any `create_agent("my_agent", ...)`).

### 4. Use it

- `create_agent("my_agent", llm_engine_name="gpt-4o-mini", ...)` or pass `agent_name="my_agent"` into your solver entrypoint.

### Format and conventions

- **Class-level metadata** (optional but recommended): `AGENT_NAME`, `AGENT_DESCRIPTION`.
- **Constructor**: accept `llm_engine_name` and `verbose` at minimum; tool-based agents accept `enabled_tools`, `enable_faiss_retrieval`, etc., and call `super().__init__(...)` with them.
- **`solve(question, **kwargs)`**: return a dict with at least the output field your pipeline expects (e.g. `direct_output`, `final_output`).
- **Logging**: use `self.log(message, level)` if your base provides it (e.g. via `AgentDisplayMixin`).

**Minimal agent (no tools)**

```python
from opentools.agents import register_agent
from opentools.agents.base_agent import BaseAgent

class MyAgent(BaseAgent):
    AGENT_NAME = "MyAgent"
    AGENT_DESCRIPTION = "Custom agent"

    def get_agent_name(self):
        return self.AGENT_NAME

    def get_agent_description(self):
        return self.AGENT_DESCRIPTION

    def solve(self, question: str, **kwargs):
        return {"direct_output": f"Echo: {question}"}

register_agent("my_agent", MyAgent)
```

**Minimal tool-based agent**

```python
from opentools.agents import register_agent
from opentools.agents.tool_based_agent import ToolBasedAgent
from opentools.core.factory import create_llm_engine

class MyToolAgent(ToolBasedAgent):
    AGENT_NAME = "MyToolAgent"
    AGENT_DESCRIPTION = "Custom tool-using agent"

    def setup_reasoning_components(self):
        self.llm_engine = create_llm_engine(model_string=self.llm_engine_name, is_multimodal=True)

    def get_agent_name(self):
        return self.AGENT_NAME

    def get_agent_description(self):
        return self.AGENT_DESCRIPTION

    def solve(self, question: str, **kwargs):
        tools = self.get_relevant_tools(question)
        # Your prompting and tool-call logic; then:
        # executions, failures = self.execute_tool(tool_calls, question)
        return {"direct_output": "Custom result"}

register_agent("my_tool_agent", MyToolAgent)
```

---

## Notes

- Tool-based agents rely on `opentools.models.Initializer` and the core tool registry for discovery and metadata.
- ReAct adapts its prompt when the model does not support structured tool-call schemas (e.g. non-OpenAI families).
