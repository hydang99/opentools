{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenTools Agents Demo with Retrieval + Image (ReAct, OctoTools, OpenTools)\n",
        "\n",
        "This notebook shows how **ReAct**, **OctoTools**, and **OpenTools** use tools for a **single image-based task** that can also benefit from web retrieval.\n",
        "\n",
        "**Task:** Use tools to look at the illusion image in `docs/assets/image.jpg` and answer which orange circle **appears** bigger (left or right), and briefly explain the illusion.\n",
        "\n",
        "**Table of contents**\n",
        "\n",
        "1. Setup\n",
        "2. ReAct with retrieval + image\n",
        "3. OctoTools with retrieval + image\n",
        "4. OpenTools with retrieval + image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "Run this once to configure imports and helper utilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04114d51",
      "metadata": {},
      "source": [
        "### How these agents behave (with retrieval + image)\n",
        "\n",
        "In this retrieval+image demo, each agent wraps the same core ideas as in `2_agent_running.ipynb`, but now they can also use tools like `Visual_AI_Tool` and web / retrieval tools:\n",
        "\n",
        "- **ReAct**: Uses a Thought ‚Üí Action (tool) ‚Üí Observation loop, deciding when to call visual or retrieval tools and when to stop with a Final Answer.\n",
        "- **OctoTools**: Builds an explicit plan, chooses tools, and writes intermediate notes into memory (you‚Äôll see sections like *Query Analysis*, *Action Prediction*, *Command Generation*, *Command Execution*, and *Context Verification* before the final answer).\n",
        "- **OpenTools**: Breaks the overall question into **sub-problems**, assigns each to a specialized sub-agent (e.g. search-oriented), routes tool calls through a generator/executor, and then verifies and aggregates results via a verifier + global memory.\n",
        "\n",
        "When you scroll through the outputs:\n",
        "- Treat the long logs as a **trace** of decisions and tool calls.\n",
        "- The **final answer** is always clearly marked (and also stored in `direct_output` / `final_output` in the returned Python dict), so you can skim the trace or jump straight to the summary depending on what you care about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5fb8cfd7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hydang/miniconda3/envs/opentools_submit/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "sys.path.insert(0, \"..\")\n",
        "sys.path.insert(0, \"src\")\n",
        "from opentools import UnifiedSolver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3346733f",
      "metadata": {},
      "source": [
        "## 2. ReAct with vs. without Tool Retrieval (All Tools Available)\n",
        "\n",
        "ReAct alternates between **Thought ‚Üí Action (tool) ‚Üí Observation**. In this section we enable **all tools** and compare two settings:\n",
        "\n",
        "- **(a) Tool retrieval disabled**: the agent sees the entire toolset context.\n",
        "- **(b) Tool retrieval enabled**: the agent first retrieves a smaller, relevant subset of tools.\n",
        "\n",
        "The goal is to demonstrate how **tool retrieval simplifies the agent‚Äôs context** and reduces overall token usage while preserving correctness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473265a8",
      "metadata": {},
      "source": [
        "### a. Tool Retrieval **disabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c934f8a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[14:37:17][ReAct][INFO] Initializing ReAct reasoning components üß†...\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] ReAct reasoning components initialized successfully üß†\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Enable FAISS retrieval: False at ReAct\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Enabled tools üîß: ['all']\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Initializing tool-based agent components...\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Initializing tool capabilities...\u001b[0m\n",
            "Error loading module tool: cannot import name 'BrowserProfile' from 'browser_use' (/Users/hydang/miniconda3/envs/opentools_submit/lib/python3.11/site-packages/browser_use/__init__.py)\n",
            "Warning: ffmpeg not found. Some audio processing features may not work.\n",
            "Please install ffmpeg to enable full audio processing capabilities.\n",
            "Error loading module tool: invalid syntax (tool.py, line 192)\n",
            "Warning: ffmpeg not found. Some audio processing features may not work.\n",
            "Please install ffmpeg to enable full audio processing capabilities.\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Available tools that is successfully loaded üîß: ['Generalist_Solution_Generator_Tool', 'Video_Processing_Tool', 'Calendar_Calculation_Tool', 'Nature_News_Fetcher_Tool', 'Google_Search_Octotools_Tool', 'Text_Detector_Tool', 'Calculator_Tool', 'Maze_Solving_Tool', 'Pubmed_Search_Tool', 'Arxiv_Paper_Search_Tool', 'Xlsxe_Extraction_Tool', 'Math_Solver_Tool', 'Simple_ArXiv_Paper_Search_Tool', 'N_Queens_Solving_Tool', 'Advanced_Object_Detector_Tool', 'Relevant_Patch_Zoomer_Tool', 'Wiki_Search_Tool', 'Doc_Extraction_Tool', 'Youtube_Tool', 'Search_Engine_Tool', 'Download_File_Tool', 'Yahoo_Finance_Tool', 'Rubik_Cube_Solver_Tool', 'Wikipedia_Knowledge_Searcher_Octotools_Tool', 'Url_Text_Extractor_Octotools_Tool', 'Plain_Text_Extraction_Tool', 'Board_Title_Solver_Tool', 'Code_Generate_Execute_Tool', 'Target_Solver_Tool', 'Visual_AI_Tool', 'Audio_Processing_Tool', 'Pdf_Extraction_Tool', 'URL_Text_Extractor_Tool', 'Woodslide_Solver_Tool', 'Csv_Extraction_Tool', 'Chemistry_Search_Tool', 'Wolfram_Math_Tool', 'Archived_Tool', 'Pptx_Extraction_Tool', 'Colour_Hue_Solver_Tool']\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Tool capabilities initialized successfully\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] FAISS tool retrieval disabled - using all available tools\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Tool-based agent components initialized successfully\u001b[0m\n",
            "UnifiedSolver initialized with agent: ReAct\n",
            "Agent description: Reasoning and Acting agent - alternates between thinking and tool usage\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Received question: Use tool to solve this question, calculate 10 * 10 + 5\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Using all available tools: ['Generalist_Solution_Generator_Tool', 'Video_Processing_Tool', 'Calendar_Calculation_Tool', 'Nature_News_Fetcher_Tool', 'Google_Search_Octotools_Tool', 'Text_Detector_Tool', 'Calculator_Tool', 'Maze_Solving_Tool', 'Pubmed_Search_Tool', 'Arxiv_Paper_Search_Tool', 'Xlsxe_Extraction_Tool', 'Math_Solver_Tool', 'Simple_ArXiv_Paper_Search_Tool', 'N_Queens_Solving_Tool', 'Advanced_Object_Detector_Tool', 'Relevant_Patch_Zoomer_Tool', 'Wiki_Search_Tool', 'Doc_Extraction_Tool', 'Youtube_Tool', 'Search_Engine_Tool', 'Download_File_Tool', 'Yahoo_Finance_Tool', 'Rubik_Cube_Solver_Tool', 'Wikipedia_Knowledge_Searcher_Octotools_Tool', 'Url_Text_Extractor_Octotools_Tool', 'Plain_Text_Extraction_Tool', 'Board_Title_Solver_Tool', 'Code_Generate_Execute_Tool', 'Target_Solver_Tool', 'Visual_AI_Tool', 'Audio_Processing_Tool', 'Pdf_Extraction_Tool', 'URL_Text_Extractor_Tool', 'Woodslide_Solver_Tool', 'Csv_Extraction_Tool', 'Chemistry_Search_Tool', 'Wolfram_Math_Tool', 'Archived_Tool', 'Pptx_Extraction_Tool', 'Colour_Hue_Solver_Tool']\u001b[0m\n",
            "\u001b[94m[14:37:17][ReAct][INFO] Starting ReAct reasoning and acting loop üí≠...\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 1: ReAct Reasoning Cycle 1\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:37:17][ReAct][DEBUG] Tracing from previous steps: {}\u001b[0m\n",
            "\u001b[90m[14:37:17][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:37:28][ReAct][INFO] Got response from LLM: {'text': 'Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.', 'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"multiply\",\"values\":[10,10]}'}]}\u001b[0m\n",
            "\u001b[90m[14:37:28][ReAct][DEBUG] Command: ‚öôÔ∏è [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}]\u001b[0m\n",
            "Module name: opentools.tools.calculator.tool\n",
            "\u001b[95m[14:37:28][ReAct][RESULT] Observation: üëÅÔ∏è [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'multiply', 'values': [10, 10]}, 'execution_result': {'result': '100', 'success': True}, 'ok': True}]\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 2: ReAct Reasoning Cycle 2\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:37:28][ReAct][DEBUG] Tracing from previous steps: {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}}\u001b[0m\n",
            "\u001b[90m[14:37:28][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:37:33][ReAct][INFO] Got response from LLM: {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"add\",\"values\":[100,5]}'}]}\u001b[0m\n",
            "\u001b[90m[14:37:33][ReAct][DEBUG] Command: ‚öôÔ∏è [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}]\u001b[0m\n",
            "Module name: opentools.tools.calculator.tool\n",
            "\u001b[95m[14:37:33][ReAct][RESULT] Observation: üëÅÔ∏è [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'add', 'values': [100, 5]}, 'execution_result': {'result': '105', 'success': True}, 'ok': True}]\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 3: ReAct Reasoning Cycle 3\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:37:33][ReAct][DEBUG] Tracing from previous steps: {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}, \"Agent Step 2\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}], \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"add\", \"values\": [100, 5]}, \"execution_result\": {\"result\": \"105\", \"success\": true}, \"ok\": true}]}}\u001b[0m\n",
            "\u001b[90m[14:37:33][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}, \"Agent Step 2\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}], \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"add\", \"values\": [100, 5]}, \"execution_result\": {\"result\": \"105\", \"success\": true}, \"ok\": true}]}}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:37:38][ReAct][INFO] Got response from LLM: Thought: I already used the calculator tool to compute 10 * 10 = 100 and then added 5 to get 105. No further calculations or tool calls are needed.\n",
            "Action: Return the final result.\n",
            "\n",
            "Final Answer: 105\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO] Reach final answer\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[92m============================================================\n",
            "üéØ FINAL ANSWER\n",
            "============================================================\u001b[0m\n",
            "\u001b[92m105\u001b[0m\n",
            "\u001b[92m============================================================\u001b[0m\n",
            "\n",
            "\u001b[92m[14:37:38][ReAct][SUCCESS] ‚úì Step 3 completed in 5.04s: Final answer reached\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO] Token Usage Summary:\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO]   Total tokens: 41111\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO]   Prompt tokens: 39685\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO]   Completion tokens: 1426\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO]   API calls: 3\u001b[0m\n",
            "\u001b[94m[14:37:38][ReAct][INFO] ReAct completed in 20.48 seconds\u001b[0m\n",
            "\n",
            "\u001b[94müìä EXECUTION SUMMARY\n",
            "==================================================\n",
            "Agent: ReAct\n",
            "Total Steps: 3\n",
            "Total Time: 21.34s\n",
            "==================================================\n",
            "‚úì Step 1: ReAct Reasoning Cycle 1 (0.00s)\n",
            "‚úì Step 2: ReAct Reasoning Cycle 2 (0.00s)\n",
            "‚úì Step 3: ReAct Reasoning Cycle 3 (5.04s)\n",
            "==================================================\u001b[0m\n",
            "\n",
            "ReAct (all tools without any tool retrieval) {'query': 'Use tool to solve this question, calculate 10 * 10 + 5', 'image': None, 'steps_taken': 3, 'agent': 'ReAct', 'llm_engine': 'gpt-5-mini', 'reasoning_trace': {'Agent Step 1': {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"multiply\",\"values\":[10,10]}'}], 'response_text': 'Thought: I will compute 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.', 'observation': [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'multiply', 'values': [10, 10]}, 'execution_result': {'result': '100', 'success': True}, 'ok': True}]}, 'Agent Step 2': {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"add\",\"values\":[100,5]}'}], 'observation': [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'add', 'values': [100, 5]}, 'execution_result': {'result': '105', 'success': True}, 'ok': True}]}, 'Agent Step 3': {'final_response_from_llm': 'Thought: I already used the calculator tool to compute 10 * 10 = 100 and then added 5 to get 105. No further calculations or tool calls are needed.\\nAction: Return the final result.\\n\\nFinal Answer: 105', 'final_answer': '105'}}, 'token_usage': {'total_prompt_tokens': 39685, 'total_completion_tokens': 1426, 'total_tokens': 41111, 'call_count': 3, 'average_tokens_per_call': 13703.666666666666}, 'error_executions': [], 'execution_time': 20.48005723953247, 'timestamp': '2026-02-26T14:37:38.353243', 'cache_dir': 'react_cache/20260226_143717', 'full_answer': '105', 'direct_output': '105', 'solver_type': 'UnifiedSolver', 'agent_used': 'react', 'total_execution_time': 20.481509923934937}\n",
            "\n",
            "Direct output:\n",
            " 105\n"
          ]
        }
      ],
      "source": [
        "react_solver = UnifiedSolver(\n",
        "    agent_name=\"react\",\n",
        "    llm_engine_name=\"gpt-5-mini\",\n",
        "    verbose=True,\n",
        "    enabled_tools=[\n",
        "        \"all\"\n",
        "    ],\n",
        "    output_types=\"direct\",\n",
        "    enable_faiss_retrieval=False,\n",
        ")\n",
        "\n",
        "react_question = (\n",
        "    \"Use tool to solve this question, calculate 10 * 10 + 5\"\n",
        ")\n",
        "\n",
        "react_result = react_solver.solve(\n",
        "    question=react_question,\n",
        ")\n",
        "\n",
        "print(\"ReAct (all tools without any tool retrieval)\", react_result)\n",
        "print(\"\\nDirect output:\\n\", react_result.get(\"direct_output\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e38861",
      "metadata": {},
      "source": [
        "### b. Tool Retrieval **enabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ab5500c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[14:37:59][ReAct][INFO] Initializing ReAct reasoning components üß†...\u001b[0m\n",
            "\u001b[94m[14:37:59][ReAct][INFO] ReAct reasoning components initialized successfully üß†\u001b[0m\n",
            "\u001b[94m[14:37:59][ReAct][INFO] Enable FAISS retrieval: True at ReAct\u001b[0m\n",
            "\u001b[94m[14:37:59][ReAct][INFO] Enabled tools üîß: ['all']\u001b[0m\n",
            "\u001b[94m[14:37:59][ReAct][INFO] Initializing tool-based agent components...\u001b[0m\n",
            "\u001b[94m[14:37:59][ReAct][INFO] Initializing tool capabilities...\u001b[0m\n",
            "Error loading module tool: cannot import name 'BrowserProfile' from 'browser_use' (/Users/hydang/miniconda3/envs/opentools_submit/lib/python3.11/site-packages/browser_use/__init__.py)\n",
            "Warning: ffmpeg not found. Some audio processing features may not work.\n",
            "Please install ffmpeg to enable full audio processing capabilities.\n",
            "Error loading module tool: invalid syntax (tool.py, line 192)\n",
            "Warning: ffmpeg not found. Some audio processing features may not work.\n",
            "Please install ffmpeg to enable full audio processing capabilities.\n",
            "\u001b[94m[14:38:00][ReAct][INFO] Available tools that is successfully loaded üîß: ['Generalist_Solution_Generator_Tool', 'Video_Processing_Tool', 'Calendar_Calculation_Tool', 'Nature_News_Fetcher_Tool', 'Google_Search_Octotools_Tool', 'Text_Detector_Tool', 'Calculator_Tool', 'Maze_Solving_Tool', 'Pubmed_Search_Tool', 'Arxiv_Paper_Search_Tool', 'Xlsxe_Extraction_Tool', 'Math_Solver_Tool', 'Simple_ArXiv_Paper_Search_Tool', 'N_Queens_Solving_Tool', 'Advanced_Object_Detector_Tool', 'Relevant_Patch_Zoomer_Tool', 'Wiki_Search_Tool', 'Doc_Extraction_Tool', 'Youtube_Tool', 'Search_Engine_Tool', 'Download_File_Tool', 'Yahoo_Finance_Tool', 'Rubik_Cube_Solver_Tool', 'Wikipedia_Knowledge_Searcher_Octotools_Tool', 'Url_Text_Extractor_Octotools_Tool', 'Plain_Text_Extraction_Tool', 'Board_Title_Solver_Tool', 'Code_Generate_Execute_Tool', 'Target_Solver_Tool', 'Visual_AI_Tool', 'Audio_Processing_Tool', 'Pdf_Extraction_Tool', 'URL_Text_Extractor_Tool', 'Woodslide_Solver_Tool', 'Csv_Extraction_Tool', 'Chemistry_Search_Tool', 'Wolfram_Math_Tool', 'Archived_Tool', 'Pptx_Extraction_Tool', 'Colour_Hue_Solver_Tool']\u001b[0m\n",
            "\u001b[94m[14:38:00][ReAct][INFO] Tool capabilities initialized successfully\u001b[0m\n",
            "Loaded 37 tools into FAISS index\n",
            "\u001b[94m[14:38:00][ReAct][INFO] FAISS tool retrieval enabled\u001b[0m\n",
            "\u001b[94m[14:38:00][ReAct][INFO] Tool-based agent components initialized successfully\u001b[0m\n",
            "UnifiedSolver initialized with agent: ReAct\n",
            "Agent description: Reasoning and Acting agent - alternates between thinking and tool usage\n",
            "\u001b[94m[14:38:00][ReAct][INFO] Received question: Use tool to solve this question, calculate 10 * 10 + 5\u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "Expanded query: Use tool to solve this question, calculate 10 * 10 + 5. compute evaluate expression calculator math-solver expression-evaluator input:10 * 10 + 5 output:numeric-result show-steps text-expression\n",
            "\u001b[94m[14:38:07][ReAct][INFO] Using FAISS retrieval to get relevant tools: ['Target_Solver_Tool', 'Math_Solver_Tool', 'Calculator_Tool']\u001b[0m\n",
            "\u001b[94m[14:38:07][ReAct][INFO] Starting ReAct reasoning and acting loop üí≠...\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 1: ReAct Reasoning Cycle 1\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:38:07][ReAct][DEBUG] Tracing from previous steps: {}\u001b[0m\n",
            "\u001b[90m[14:38:07][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:38:14][ReAct][INFO] Got response from LLM: {'text': 'Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.', 'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"multiply\",\"values\":[10,10]}'}]}\u001b[0m\n",
            "\u001b[90m[14:38:14][ReAct][DEBUG] Command: ‚öôÔ∏è [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}]\u001b[0m\n",
            "Module name: opentools.tools.calculator.tool\n",
            "\u001b[95m[14:38:14][ReAct][RESULT] Observation: üëÅÔ∏è [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'multiply', 'values': [10, 10]}, 'execution_result': {'result': '100', 'success': True}, 'ok': True}]\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 2: ReAct Reasoning Cycle 2\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:38:14][ReAct][DEBUG] Tracing from previous steps: {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}}\u001b[0m\n",
            "\u001b[90m[14:38:14][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:38:19][ReAct][INFO] Got response from LLM: {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"add\",\"values\":[100,5]}'}]}\u001b[0m\n",
            "\u001b[90m[14:38:19][ReAct][DEBUG] Command: ‚öôÔ∏è [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}]\u001b[0m\n",
            "Module name: opentools.tools.calculator.tool\n",
            "\u001b[95m[14:38:19][ReAct][RESULT] Observation: üëÅÔ∏è [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'add', 'values': [100, 5]}, 'execution_result': {'result': '105', 'success': True}, 'ok': True}]\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 3: ReAct Reasoning Cycle 3\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:38:19][ReAct][DEBUG] Tracing from previous steps: {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}, \"Agent Step 2\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}], \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"add\", \"values\": [100, 5]}, \"execution_result\": {\"result\": \"105\", \"success\": true}, \"ok\": true}]}}\u001b[0m\n",
            "\u001b[90m[14:38:19][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Use tool to solve this question, calculate 10 * 10 + 5\n",
            "            Image (if any): None\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"values\\\":[10,10]}\"}], \"response_text\": \"Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.\", \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"multiply\", \"values\": [10, 10]}, \"execution_result\": {\"result\": \"100\", \"success\": true}, \"ok\": true}]}, \"Agent Step 2\": {\"tool_calls\": [{\"name\": \"Calculator_Tool\", \"arguments\": \"{\\\"operation\\\":\\\"add\\\",\\\"values\\\":[100,5]}\"}], \"observation\": [{\"index\": 0, \"name\": \"Calculator_Tool\", \"args\": {\"operation\": \"add\", \"values\": [100, 5]}, \"execution_result\": {\"result\": \"105\", \"success\": true}, \"ok\": true}]}}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:38:23][ReAct][INFO] Got response from LLM: Thought: I have calculated 10 * 10 = 100 and then added 5 to get 105; I am ready to provide the final answer.\n",
            "Action: State the final result.\n",
            "\n",
            "Final Answer: 105\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO] Reach final answer\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[92m============================================================\n",
            "üéØ FINAL ANSWER\n",
            "============================================================\u001b[0m\n",
            "\u001b[92m105\u001b[0m\n",
            "\u001b[92m============================================================\u001b[0m\n",
            "\n",
            "\u001b[92m[14:38:23][ReAct][SUCCESS] ‚úì Step 3 completed in 4.73s: Final answer reached\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO] Token Usage Summary:\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO]   Total tokens: 6133\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO]   Prompt tokens: 4409\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO]   Completion tokens: 1724\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO]   API calls: 4\u001b[0m\n",
            "\u001b[94m[14:38:23][ReAct][INFO] ReAct completed in 23.64 seconds\u001b[0m\n",
            "\n",
            "\u001b[94müìä EXECUTION SUMMARY\n",
            "==================================================\n",
            "Agent: ReAct\n",
            "Total Steps: 3\n",
            "Total Time: 24.48s\n",
            "==================================================\n",
            "‚úì Step 1: ReAct Reasoning Cycle 1 (0.00s)\n",
            "‚úì Step 2: ReAct Reasoning Cycle 2 (0.00s)\n",
            "‚úì Step 3: ReAct Reasoning Cycle 3 (4.73s)\n",
            "==================================================\u001b[0m\n",
            "\n",
            "ReAct (all tools without any tool retrieval) {'query': 'Use tool to solve this question, calculate 10 * 10 + 5', 'image': None, 'steps_taken': 3, 'agent': 'ReAct', 'llm_engine': 'gpt-5-mini', 'reasoning_trace': {'Agent Step 1': {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"multiply\",\"values\":[10,10]}'}], 'response_text': 'Thought: Calculate 10 * 10 first using the calculator tool.\\nAction: Call the calculator tool to multiply 10 and 10.', 'observation': [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'multiply', 'values': [10, 10]}, 'execution_result': {'result': '100', 'success': True}, 'ok': True}]}, 'Agent Step 2': {'tool_calls': [{'name': 'Calculator_Tool', 'arguments': '{\"operation\":\"add\",\"values\":[100,5]}'}], 'observation': [{'index': 0, 'name': 'Calculator_Tool', 'args': {'operation': 'add', 'values': [100, 5]}, 'execution_result': {'result': '105', 'success': True}, 'ok': True}]}, 'Agent Step 3': {'final_response_from_llm': 'Thought: I have calculated 10 * 10 = 100 and then added 5 to get 105; I am ready to provide the final answer.\\nAction: State the final result.\\n\\nFinal Answer: 105', 'final_answer': '105'}}, 'token_usage': {'total_prompt_tokens': 4409, 'total_completion_tokens': 1724, 'total_tokens': 6133, 'call_count': 4, 'average_tokens_per_call': 1533.25}, 'error_executions': [], 'execution_time': 23.639406204223633, 'timestamp': '2026-02-26T14:38:23.987031', 'cache_dir': 'react_cache/20260226_143800', 'full_answer': '105', 'direct_output': '105', 'solver_type': 'UnifiedSolver', 'agent_used': 'react', 'total_execution_time': 23.640266180038452}\n",
            "\n",
            "Direct output:\n",
            " 105\n"
          ]
        }
      ],
      "source": [
        "react_solver = UnifiedSolver(\n",
        "    agent_name=\"react\",\n",
        "    llm_engine_name=\"gpt-5-mini\",\n",
        "    verbose=True,\n",
        "    enabled_tools=[\n",
        "        \"all\"\n",
        "    ],\n",
        "    output_types=\"direct\",\n",
        "    enable_faiss_retrieval=True, #enable tool retrieval here\n",
        ")\n",
        "\n",
        "react_question = (\n",
        "    \"Use tool to solve this question, calculate 10 * 10 + 5\"\n",
        ")\n",
        "\n",
        "react_result = react_solver.solve(\n",
        "    question=react_question,\n",
        ")\n",
        "\n",
        "print(\"ReAct (all tools without any tool retrieval)\", react_result)\n",
        "print(\"\\nDirect output:\\n\", react_result.get(\"direct_output\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad70b73",
      "metadata": {},
      "source": [
        "In both runs, ReAct returns the same correct answer (`105`), but the **token cost differs dramatically** depending on whether **tool retrieval** is enabled. With **tool retrieval enabled**, the agent uses **6,133 total tokens** versus **41,111 total tokens** without retrieval‚Äîabout a **6.7√ó reduction** in total tokens (‚âà **85% fewer**). This illustrates how tool retrieval can reduce prompt bloat when many tools are available, by selecting a smaller, more relevant tool subset for the agent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cef1ac1",
      "metadata": {},
      "source": [
        "## 3. ReAct with retrieval + image\n",
        "\n",
        "ReAct alternates between **Thought ‚Üí Action (tool) ‚Üí Observation**. Here we\n",
        "enable both **visual** and **retrieval** tools, but keep the task to a single,\n",
        "simple question about the illusion image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9e48b12f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[14:29:00][ReAct][INFO] Initializing ReAct reasoning components üß†...\u001b[0m\n",
            "\u001b[94m[14:29:01][ReAct][INFO] ReAct reasoning components initialized successfully üß†\u001b[0m\n",
            "\u001b[94m[14:29:01][ReAct][INFO] Enable FAISS retrieval: True at ReAct\u001b[0m\n",
            "\u001b[94m[14:29:01][ReAct][INFO] Enabled tools üîß: ['Visual_AI_Tool', 'Search_Engine_Tool', 'Wiki_Search_Tool', 'URL_Text_Extractor_Tool']\u001b[0m\n",
            "\u001b[94m[14:29:01][ReAct][INFO] Initializing tool-based agent components...\u001b[0m\n",
            "\u001b[94m[14:29:01][ReAct][INFO] Initializing tool capabilities...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-26 14:29:02 Hys-MacBook-Air-2.local metapub.config[33744] WARNING NCBI_API_KEY was not set.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[14:29:03][ReAct][INFO] Available tools that is successfully loaded üîß: ['Wiki_Search_Tool', 'Search_Engine_Tool', 'Visual_AI_Tool', 'URL_Text_Extractor_Tool']\u001b[0m\n",
            "\u001b[94m[14:29:03][ReAct][INFO] Tool capabilities initialized successfully\u001b[0m\n",
            "Loaded 37 tools into FAISS index\n",
            "\u001b[94m[14:29:04][ReAct][INFO] FAISS tool retrieval enabled\u001b[0m\n",
            "\u001b[94m[14:29:04][ReAct][INFO] Tool-based agent components initialized successfully\u001b[0m\n",
            "UnifiedSolver initialized with agent: ReAct\n",
            "Agent description: Reasoning and Acting agent - alternates between thinking and tool usage\n",
            "\u001b[94m[14:29:04][ReAct][INFO] Received question: Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.\u001b[0m\n",
            "\u001b[94m[14:29:04][ReAct][INFO] Received image: ../assets/image.jpg\u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "Expanded query: Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.. image viewer display image_path, breed classifier predict dog breed, color detector detect dominant dog coat color, object detector identify objects beside dog and return labels and bounding boxes, image captioner generate concise caption, image qa answer color breed and nearby object, input:image_path or image_url, output:one or two short sentences\n",
            "\u001b[94m[14:29:14][ReAct][INFO] Using FAISS retrieval to get relevant tools: ['Visual_AI_Tool']\u001b[0m\n",
            "\u001b[94m[14:29:14][ReAct][INFO] Starting ReAct reasoning and acting loop üí≠...\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 1: ReAct Reasoning Cycle 1\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:29:14][ReAct][DEBUG] Tracing from previous steps: {}\u001b[0m\n",
            "\u001b[90m[14:29:14][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.\n",
            "            Image (if any): ../assets/image.jpg\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:29:19][ReAct][INFO] Got response from LLM: {'text': \"Thought: I will analyze the image to identify the dog's color, breed, and what it is lying next to. Action: Call the visual analysis tool on the provided image with a prompt asking for the dog's color, breed, and the object it lies next to.\", 'tool_calls': [{'name': 'Visual_AI_Tool', 'arguments': '{\"image_path\":\"../assets/image.jpg\",\"prompt\":\"Identify the dog\\'s primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}'}]}\u001b[0m\n",
            "\u001b[90m[14:29:19][ReAct][DEBUG] Command: ‚öôÔ∏è [{\"name\": \"Visual_AI_Tool\", \"arguments\": \"{\\\"image_path\\\":\\\"../assets/image.jpg\\\",\\\"prompt\\\":\\\"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\\\"}\"}]\u001b[0m\n",
            "Module name: opentools.tools.visual_ai.tool\n",
            "Deleted uploaded file file-Y9yowiekSU6Mdaokun5uUg to avoid storage costs\n",
            "\u001b[95m[14:29:23][ReAct][RESULT] Observation: üëÅÔ∏è [{'index': 0, 'name': 'Visual_AI_Tool', 'args': {'image_path': '../assets/image.jpg', 'prompt': \"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}, 'execution_result': {'result': '- Primary color: White (light cream)\\n- Likely breed: Labrador Retriever (yellow lab)\\n- Lying next to: A bicycle', 'success': True, 'token_usage': {'total_prompt_tokens': 1232, 'total_completion_tokens': 1109, 'total_tokens': 2341, 'call_count': 3, 'average_tokens_per_call': 780.3333333333334}}, 'ok': True}]\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 2: ReAct Reasoning Cycle 2\n",
            "============================================================\u001b[0m\n",
            "\u001b[90m[14:29:23][ReAct][DEBUG] Tracing from previous steps: {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Visual_AI_Tool\", \"arguments\": \"{\\\"image_path\\\":\\\"../assets/image.jpg\\\",\\\"prompt\\\":\\\"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\\\"}\"}], \"response_text\": \"Thought: I will analyze the image to identify the dog's color, breed, and what it is lying next to. Action: Call the visual analysis tool on the provided image with a prompt asking for the dog's color, breed, and the object it lies next to.\", \"observation\": [{\"index\": 0, \"name\": \"Visual_AI_Tool\", \"args\": {\"image_path\": \"../assets/image.jpg\", \"prompt\": \"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}, \"execution_result\": {\"result\": \"- Primary color: White (light cream)\\n- Likely breed: Labrador Retriever (yellow lab)\\n- Lying next to: A bicycle\", \"success\": true, \"token_usage\": {\"total_prompt_tokens\": 1232, \"total_completion_tokens\": 1109, \"total_tokens\": 2341, \"call_count\": 3, \"average_tokens_per_call\": 780.3333333333334}}, \"ok\": true}]}}\u001b[0m\n",
            "\u001b[90m[14:29:23][ReAct][DEBUG] ReAct prompt: \n",
            "            Question: Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.\n",
            "            Image (if any): ../assets/image.jpg\n",
            "            File (if any): None\n",
            "            You should follow this exact format:\n",
            "            Thought: [your reasoning about current step and what to do next.]\n",
            "            Action: [The action to take in this step]\n",
            "\n",
            "            When you have enough information to answer the question, return the Final Answer following:\n",
            "            Final Answer: [your final answer]\n",
            "\n",
            "            Important:\n",
            "            - This Thought/Action can repeat as needed.\n",
            "            - Observation in current trace is the result of the action taken in the previous step.\n",
            "            - End with \"Final Answer:\" when you're done\n",
            "            - Never use placeholder values in arguments; always use real values.\n",
            "            - Once a tool returns the metric you need, DO NOT call any tool again; restate the key answers and keep reasoning without calling that same tool/arguments again.\n",
            "            - Only call a tool again if you change the arguments to obtain new information; otherwise switch tools or answer directly using existing observations.\n",
            "            - For multiple-choice questions, compute the required value, match it to the listed options, and make your last line exactly `Answer: LETTER`.\n",
            "            - CRITICAL: If previous steps resulted in an error mentioning \"repeated\" or \"same tool command\", you MUST NOT try the same tool command again‚Äîuse the information already gathered or try a different approach.\n",
            "            Current trace:\n",
            "            {\"Agent Step 1\": {\"tool_calls\": [{\"name\": \"Visual_AI_Tool\", \"arguments\": \"{\\\"image_path\\\":\\\"../assets/image.jpg\\\",\\\"prompt\\\":\\\"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\\\"}\"}], \"response_text\": \"Thought: I will analyze the image to identify the dog's color, breed, and what it is lying next to. Action: Call the visual analysis tool on the provided image with a prompt asking for the dog's color, breed, and the object it lies next to.\", \"observation\": [{\"index\": 0, \"name\": \"Visual_AI_Tool\", \"args\": {\"image_path\": \"../assets/image.jpg\", \"prompt\": \"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}, \"execution_result\": {\"result\": \"- Primary color: White (light cream)\\n- Likely breed: Labrador Retriever (yellow lab)\\n- Lying next to: A bicycle\", \"success\": true, \"token_usage\": {\"total_prompt_tokens\": 1232, \"total_completion_tokens\": 1109, \"total_tokens\": 2341, \"call_count\": 3, \"average_tokens_per_call\": 780.3333333333334}}, \"ok\": true}]}}\n",
            "            \u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:29:31][ReAct][INFO] Got response from LLM: Thought: I have the visual analysis results identifying the dog's color, likely breed, and the object it's next to, so I'll use that to answer directly.  \n",
            "Action: No further tools needed; provide the final concise answer.\n",
            "\n",
            "Final Answer: The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO] Reach final answer\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[92m============================================================\n",
            "üéØ FINAL ANSWER\n",
            "============================================================\u001b[0m\n",
            "\u001b[92mThe dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.\u001b[0m\n",
            "\u001b[92m============================================================\u001b[0m\n",
            "\n",
            "\u001b[92m[14:29:31][ReAct][SUCCESS] ‚úì Step 2 completed in 7.65s: Final answer reached\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO] Token Usage Summary:\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO]   Total tokens: 3667\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO]   Prompt tokens: 2130\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO]   Completion tokens: 1537\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO]   API calls: 4\u001b[0m\n",
            "\u001b[94m[14:29:31][ReAct][INFO] ReAct completed in 27.60 seconds\u001b[0m\n",
            "\n",
            "\u001b[94müìä EXECUTION SUMMARY\n",
            "==================================================\n",
            "Agent: ReAct\n",
            "Total Steps: 2\n",
            "Total Time: 30.67s\n",
            "==================================================\n",
            "‚úì Step 1: ReAct Reasoning Cycle 1 (0.00s)\n",
            "‚úì Step 2: ReAct Reasoning Cycle 2 (7.65s)\n",
            "==================================================\u001b[0m\n",
            "\n",
            "ReAct (retrieval + image) {'query': 'Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.', 'image': '../assets/image.jpg', 'steps_taken': 2, 'agent': 'ReAct', 'llm_engine': 'gpt-5-mini', 'reasoning_trace': {'Agent Step 1': {'tool_calls': [{'name': 'Visual_AI_Tool', 'arguments': '{\"image_path\":\"../assets/image.jpg\",\"prompt\":\"Identify the dog\\'s primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}'}], 'response_text': \"Thought: I will analyze the image to identify the dog's color, breed, and what it is lying next to. Action: Call the visual analysis tool on the provided image with a prompt asking for the dog's color, breed, and the object it lies next to.\", 'observation': [{'index': 0, 'name': 'Visual_AI_Tool', 'args': {'image_path': '../assets/image.jpg', 'prompt': \"Identify the dog's primary color, likely breed, and what object or item the dog is lying next to. Provide concise answers.\"}, 'execution_result': {'result': '- Primary color: White (light cream)\\n- Likely breed: Labrador Retriever (yellow lab)\\n- Lying next to: A bicycle', 'success': True, 'token_usage': {'total_prompt_tokens': 1232, 'total_completion_tokens': 1109, 'total_tokens': 2341, 'call_count': 3, 'average_tokens_per_call': 780.3333333333334}}, 'ok': True}]}, 'Agent Step 2': {'final_response_from_llm': \"Thought: I have the visual analysis results identifying the dog's color, likely breed, and the object it's next to, so I'll use that to answer directly.  \\nAction: No further tools needed; provide the final concise answer.\\n\\nFinal Answer: The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.\", 'final_answer': 'The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.'}}, 'token_usage': {'total_prompt_tokens': 2130, 'total_completion_tokens': 1537, 'total_tokens': 3667, 'call_count': 4, 'average_tokens_per_call': 916.75}, 'error_executions': [], 'execution_time': 27.60331916809082, 'timestamp': '2026-02-26T14:29:31.622741', 'cache_dir': 'react_cache/20260226_142904', 'full_answer': 'The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.', 'direct_output': 'The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.', 'solver_type': 'UnifiedSolver', 'agent_used': 'react', 'total_execution_time': 27.604169130325317}\n",
            "\n",
            "Direct output:\n",
            " The dog is a light cream/white Labrador Retriever (yellow lab) and it is lying next to a bicycle.\n"
          ]
        }
      ],
      "source": [
        "react_solver = UnifiedSolver(\n",
        "    agent_name=\"react\",\n",
        "    llm_engine_name=\"gpt-5-mini\",\n",
        "    verbose=True,\n",
        "    enabled_tools=[\n",
        "        \"Visual_AI_Tool\",\n",
        "        \"Search_Engine_Tool\",\n",
        "        \"Wiki_Search_Tool\",\n",
        "        \"URL_Text_Extractor_Tool\",\n",
        "    ],\n",
        "    output_types=\"direct\",\n",
        "    enable_faiss_retrieval=True,\n",
        ")\n",
        "\n",
        "react_question = (\n",
        "    \"Look at the provided image and use tools as needed. \"\n",
        "    \"Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? \"\n",
        "    \"Answer in one or two short sentences.\"\n",
        ")\n",
        "\n",
        "react_result = react_solver.solve(\n",
        "    question=react_question,\n",
        "    image_path=r\"../assets/image.jpg\",\n",
        ")\n",
        "\n",
        "print(\"ReAct (retrieval + image)\", react_result)\n",
        "print(\"\\nDirect output:\\n\", react_result.get(\"direct_output\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d17390",
      "metadata": {},
      "source": [
        "## 4. OpenTools with retrieval + image\n",
        "\n",
        "OpenTools uses a planner‚Äìgenerator‚Äìexecutor loop over tools. We configure it\n",
        "with the same visual + retrieval tools and the same illusion question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b0c4490d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[14:30:16][OpenTools][INFO] Enabled tools üîß: ['Visual_AI_Tool', 'Search_Engine_Tool', 'Wiki_Search_Tool', 'URL_Text_Extractor_Tool']\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Initializing tool-based agent components...\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Initializing tool capabilities...\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Available tools that is successfully loaded üîß: ['Wiki_Search_Tool', 'Search_Engine_Tool', 'Visual_AI_Tool', 'URL_Text_Extractor_Tool']\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Tool capabilities initialized successfully\u001b[0m\n",
            "Loaded 37 tools into FAISS index\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] FAISS tool retrieval enabled\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Tool-based agent components initialized successfully\u001b[0m\n",
            "UnifiedSolver initialized with agent: OpenTools\n",
            "Agent description: OpenTools agent - uses tools to solve problems\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Received question: Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Received image: ../assets/image.jpg\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Starting OpenTools reasoning and acting loop üí≠...\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] #########################################################\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 1: OpenTools Reasoning Cycle 1\n",
            "============================================================\u001b[0m\n",
            "\u001b[94m[14:30:16][OpenTools][INFO] Start reasoning agent: \u001b[0m\n",
            "Using structured output model: gpt-5-mini\n",
            "\u001b[94m[14:30:21][OpenTools][INFO] Reasoning agent response: sub_problem='Analyze the provided image ../assets/image.jpg and report (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the results as one or two short sentences.' sub_agent='Visual-Agent' supporting_documents='../assets/image.jpg' stop=False answer=''\u001b[0m\n",
            "\u001b[94m[14:30:21][OpenTools][INFO] Start Generator agent to generate tool calls\u001b[0m\n",
            "Using reasoning model: gpt-5-mini\n",
            "\u001b[94m[14:30:26][OpenTools][INFO] Generated Tool calls: [{'name': 'Visual_AI_Tool', 'arguments': '{\"image_path\":\"../assets/image.jpg\",\"prompt\":\"Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\"}'}]\u001b[0m\n",
            "\u001b[94m[14:30:26][OpenTools][INFO] Start Executor agent to execute tool calls\u001b[0m\n",
            "Module name: opentools.tools.visual_ai.tool\n",
            "Deleted uploaded file file-92VaFSig8Xy1F2LWuHM6hP to avoid storage costs\n",
            "\u001b[94m[14:30:32][OpenTools][INFO] Executed Tool calls: [{'index': 0, 'name': 'Visual_AI_Tool', 'args': {'image_path': '../assets/image.jpg', 'prompt': 'Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).'}, 'execution_result': {'result': 'The dog is primarily cream/white and looks like a Labrador Retriever (a yellow lab). It is lying next to a parked bicycle at the curb.', 'success': True, 'token_usage': {'total_prompt_tokens': 2806, 'total_completion_tokens': 910, 'total_tokens': 3716, 'call_count': 3, 'average_tokens_per_call': 1238.6666666666667}}, 'ok': True}]\u001b[0m\n",
            "\u001b[94m[14:30:32][OpenTools][INFO] Start Verifier agent to verify the tool result\u001b[0m\n",
            "Using structured output model: gpt-5-mini\n",
            "\u001b[94m[14:30:39][OpenTools][INFO] Verified Tool result: verification=True summary_result='Tool: Visual_AI_Tool\\nImage path: ../assets/image.jpg\\nPrompt (exact): \"Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\"\\nExecution result (exact): \"The dog is primarily cream/white and looks like a Labrador Retriever (a yellow lab). It is lying next to a parked bicycle at the curb.\"\\nSuccess: True\\nTool call index: 0\\nArgs provided: {\\'image_path\\': \\'../assets/image.jpg\\', \\'prompt\\': \\'Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\\'}\\nToken usage: total_prompt_tokens=2806, total_completion_tokens=910, total_tokens=3716, call_count=3, average_tokens_per_call=1238.6666666666667' reason='' suggestion=''\u001b[0m\n",
            "\u001b[94m[14:30:39][OpenTools][INFO] Global memory updated: {'Agent_Step_0': {'sub_problem': 'Analyze the provided image ../assets/image.jpg and report (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the results as one or two short sentences.', 'answer': 'Tool: Visual_AI_Tool\\nImage path: ../assets/image.jpg\\nPrompt (exact): \"Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\"\\nExecution result (exact): \"The dog is primarily cream/white and looks like a Labrador Retriever (a yellow lab). It is lying next to a parked bicycle at the curb.\"\\nSuccess: True\\nTool call index: 0\\nArgs provided: {\\'image_path\\': \\'../assets/image.jpg\\', \\'prompt\\': \\'Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\\'}\\nToken usage: total_prompt_tokens=2806, total_completion_tokens=910, total_tokens=3716, call_count=3, average_tokens_per_call=1238.6666666666667'}}\u001b[0m\n",
            "\u001b[94m[14:30:39][OpenTools][INFO] #########################################################\u001b[0m\n",
            "\n",
            "\u001b[96m============================================================\n",
            "Agent Step 2: OpenTools Reasoning Cycle 2\n",
            "============================================================\u001b[0m\n",
            "\u001b[94m[14:30:39][OpenTools][INFO] Start reasoning agent: \u001b[0m\n",
            "Using structured output model: gpt-5-mini\n",
            "\u001b[94m[14:30:44][OpenTools][INFO] Reasoning agent response: sub_problem='/None' sub_agent='/None' supporting_documents=None stop=True answer='The dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.'\u001b[0m\n",
            "Using structured output model: gpt-5-mini\n",
            "\u001b[94m[14:30:52][OpenTools][INFO] Direct output and summary: direct_output='The dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.' summary='Visual_AI_Tool analyzed ../assets/image.jpg and reported the dog is primarily cream/white, likely a Labrador Retriever (yellow lab), and is lying next to a parked bicycle at the curb.' stop=True\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO] Reach final answer: \u001b[0m\n",
            "\n",
            "\u001b[92m============================================================\n",
            "üéØ FINAL ANSWER\n",
            "============================================================\u001b[0m\n",
            "\u001b[92mThe dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.\u001b[0m\n",
            "\u001b[92m============================================================\u001b[0m\n",
            "\n",
            "\u001b[94m[14:30:52][OpenTools][INFO] Summary of step taken: Visual_AI_Tool analyzed ../assets/image.jpg and reported the dog is primarily cream/white, likely a Labrador Retriever (yellow lab), and is lying next to a parked bicycle at the curb.\u001b[0m\n",
            "\u001b[92m[14:30:52][OpenTools][SUCCESS] ‚úì Step 2 completed in 13.25s: Final answer reached\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO] Token Usage Summary:\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO]   Total tokens: 8817\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO]   Prompt tokens: 6506\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO]   Completion tokens: 2311\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO]   API calls: 6\u001b[0m\n",
            "\u001b[94m[14:30:52][OpenTools][INFO] OpenTools completed in 36.06 seconds\u001b[0m\n",
            "\n",
            "\u001b[94müìä EXECUTION SUMMARY\n",
            "==================================================\n",
            "Agent: OpenTools\n",
            "Total Steps: 2\n",
            "Total Time: 36.12s\n",
            "==================================================\n",
            "‚úì Step 1: OpenTools Reasoning Cycle 1 (0.00s)\n",
            "‚úì Step 2: OpenTools Reasoning Cycle 2 (13.25s)\n",
            "==================================================\u001b[0m\n",
            "\n",
            "OpenTools (retrieval + image) {'query': 'Look at the provided image and use tools as needed. Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? Answer in one or two short sentences.', 'image': '../assets/image.jpg', 'file_path': None, 'llm_engine': 'gpt-5-mini', 'steps_taken': 2, 'agent': 'OpenTools', 'token_usage': {'total_prompt_tokens': 6506, 'total_completion_tokens': 2311, 'total_tokens': 8817, 'call_count': 6, 'average_tokens_per_call': 1469.5}, 'reasoning_trace': {'Agent_Step_0': {'sub_problem': 'Analyze the provided image ../assets/image.jpg and report (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the results as one or two short sentences.', 'answer': 'Tool: Visual_AI_Tool\\nImage path: ../assets/image.jpg\\nPrompt (exact): \"Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\"\\nExecution result (exact): \"The dog is primarily cream/white and looks like a Labrador Retriever (a yellow lab). It is lying next to a parked bicycle at the curb.\"\\nSuccess: True\\nTool call index: 0\\nArgs provided: {\\'image_path\\': \\'../assets/image.jpg\\', \\'prompt\\': \\'Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\\'}\\nToken usage: total_prompt_tokens=2806, total_completion_tokens=910, total_tokens=3716, call_count=3, average_tokens_per_call=1238.6666666666667'}, 'final_answer': 'The dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.'}, 'error_executions': [], 'local_memory_list': [{'Agent_Step_0': {'sub_problem': 'Analyze the provided image ../assets/image.jpg and report (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the results as one or two short sentences.', 'sub_agent': 'Visual-Agent', 'supporting_documents': '../assets/image.jpg', 'tool_calls': [{'name': 'Visual_AI_Tool', 'arguments': '{\"image_path\":\"../assets/image.jpg\",\"prompt\":\"Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).\"}'}], 'tool_result': [{'index': 0, 'name': 'Visual_AI_Tool', 'args': {'image_path': '../assets/image.jpg', 'prompt': 'Analyze the image and extract these visual details: (1) the dog‚Äôs primary color, (2) the dog‚Äôs likely breed, and (3) the object or item the dog is lying next to. Provide the answer as one or two short sentences (concise).'}, 'execution_result': {'result': 'The dog is primarily cream/white and looks like a Labrador Retriever (a yellow lab). It is lying next to a parked bicycle at the curb.', 'success': True, 'token_usage': {'total_prompt_tokens': 2806, 'total_completion_tokens': 910, 'total_tokens': 3716, 'call_count': 3, 'average_tokens_per_call': 1238.6666666666667}}, 'ok': True}]}}], 'execution_time': 36.05992388725281, 'timestamp': '2026-02-26T14:30:52.850259', 'cache_dir': 'opentools_cache/20260226_143016', 'direct_output': 'The dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.', 'summary': 'Visual_AI_Tool analyzed ../assets/image.jpg and reported the dog is primarily cream/white, likely a Labrador Retriever (yellow lab), and is lying next to a parked bicycle at the curb.', 'solver_type': 'UnifiedSolver', 'agent_used': 'opentools', 'total_execution_time': 36.06061387062073}\n",
            "\n",
            "Direct output:\n",
            " The dog is cream/white and appears to be a Labrador Retriever (a yellow lab); it is lying next to a parked bicycle at the curb.\n"
          ]
        }
      ],
      "source": [
        "opentools_solver = UnifiedSolver(\n",
        "    agent_name=\"opentools\",\n",
        "    llm_engine_name=\"gpt-5-mini\",\n",
        "    verbose=True,\n",
        "    enabled_tools=[\n",
        "        \"Visual_AI_Tool\",\n",
        "        \"Search_Engine_Tool\",\n",
        "        \"Wiki_Search_Tool\",\n",
        "        \"URL_Text_Extractor_Tool\",\n",
        "    ],\n",
        "    output_types=\"direct\",\n",
        "    enable_faiss_retrieval=True,\n",
        ")\n",
        "\n",
        "opentools_question = (\n",
        "    \"Look at the provided image and use tools as needed. \"\n",
        "    \"Question: What color is the dog in the image, what breed is it, and what is the dog lying next to? \"\n",
        "    \"Answer in one or two short sentences.\"\n",
        ")\n",
        "\n",
        "opentools_result = opentools_solver.solve(\n",
        "    question=opentools_question,\n",
        "    image_path=r\"../assets/image.jpg\",\n",
        ")\n",
        "\n",
        "print(\"OpenTools (retrieval + image)\", opentools_result)\n",
        "print(\"\\nDirect output:\\n\", opentools_result.get(\"direct_output\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f008a8c6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "opentools_submit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
